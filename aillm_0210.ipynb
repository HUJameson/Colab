{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO6yU9hlFKavb1/l0fERKin",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HUJameson/Colab/blob/main/aillm_0210.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M5OhT3Fhj0KX"
      },
      "outputs": [],
      "source": [
        "#不要执行，非常耗token\n",
        "\n",
        "import os,openai,backoff\n",
        "import pandas as pd\n",
        "\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "dynasties= ['唐', '宋', '元', '明', '清', '汉', '魏', '晋', '南北朝']\n",
        "super_powers = ['隐形', '飞行', '读心术', '瞬间移动', '不死之身', '喷火']\n",
        "story_types = ['轻松', '努力', '艰难']\n",
        "\n",
        "@backoff.on_exception(backoff.expo, openai.error.RateLimitError)\n",
        "def gpt35(prompt, max_tokens=2048, temperature=0.5, top_p=1, frequency_penalty=0, presence_penalty=0):\n",
        "    response = openai.Completion.create(\n",
        "        engine=\"text-davinci-003\",\n",
        "        prompt=prompt,\n",
        "        max_tokens=max_tokens,\n",
        "        temperature=temperature,\n",
        "        top_p=top_p,\n",
        "        frequency_penalty=frequency_penalty,\n",
        "        presence_penalty=presence_penalty)\n",
        "    return response[\"choices\"][0][\"text\"]\n",
        "\n",
        "def prepare_stories(dynasties, super_powers, story_types, output_file=\"data/ultraman_stories.csv\"):\n",
        "    df = pd.DataFrame()\n",
        "    repeat = 3\n",
        "    for dynasty in dynasties:\n",
        "        for super_power in super_powers:\n",
        "            for story_type in story_types:\n",
        "                   for i in range(repeat):\n",
        "                        prompt = f\"\"\"请你用中文写一段300字的故事，情节跌宕起伏，讲述一位{dynasty}朝时期的英雄人物，穿越到现代，拥有了{super_power}这样的超能力，通过{story_type}的战斗，帮助奥特曼一起打败了怪兽的故事。\"\"\"\n",
        "                        story = gpt35(prompt)\n",
        "                        row = {\"dynasty\": dynasty, \"super_power\": super_power, \"story_type\": story_type, \"story\": story}\n",
        "                        row = pd.DataFrame([row])\n",
        "                        df = pd.concat([df, row], axis=0, ignore_index=True)\n",
        "\n",
        "    df.to_csv(output_file)\n",
        "\n",
        "prepare_stories(dynasties, super_powers, story_types)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "os.chdir(\"/content/drive/My Drive/Colab Notebooks\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zboNMUObmnYr",
        "outputId": "218d46a2-276b-4077-c0f2-602982383c3d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai\n",
        "import openai\n",
        "from sk_utils import read_sk\n",
        "openai_sk = read_sk()\n",
        "%env OPENAI_API_KEY=$openai_sk"
      ],
      "metadata": {
        "id": "wjODKp9KnGm3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"data/ultraman_stories.csv\")\n",
        "df['sub_prompt'] = df['dynasty'] + \",\" + df['super_power'] + \",\" + df['story_type']\n",
        "prepared_data = df.loc[:,['sub_prompt','story']]\n",
        "prepared_data.rename(columns={'sub_prompt':'prompt', 'story':'completion'}, inplace=True)\n",
        "prepared_data.to_csv('data/prepared_data.csv',index=False)\n",
        "\n",
        "import subprocess\n",
        "\n",
        "subprocess.run('openai tools fine_tunes.prepare_data --file data/prepared_data.csv --quiet'.split())"
      ],
      "metadata": {
        "id": "cBMngNzjkPJN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = subprocess.run('openai api fine_tunes.create --training_file data/prepared_data_prepared.jsonl --model curie --suffix \"ultraman\"'.split(), stdout=subprocess.PIPE).stdout\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZYShJoR4n4zS",
        "outputId": "588f5c87-323b-4abb-a71c-105f739531cf"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b\"Found potentially duplicated files with name 'prepared_data_prepared.jsonl', purpose 'fine-tune' and size 446199 bytes\\nfile-eoIlel2JuBwCBGq8EaYoL44f\\nfile-lujkljdVWAzs9dHFYqoIh4UY\\nEnter file ID to reuse an already uploaded file, or an empty string to upload this file anyway: Uploaded file from data/prepared_data_prepared.jsonl: file-KMS7n1GydW73gGtD58uW6Sfl\\nCreated fine-tune: ft-gUum6Ej7gYJghTfFcmdwkeHJ\\nStreaming events until fine-tuning is complete...\\n\\n(Ctrl-C will interrupt the stream, but not cancel the fine-tune)\\n[2023-10-05 02:43:17] Created fine-tune: ft-gUum6Ej7gYJghTfFcmdwkeHJ\\n[2023-10-05 02:43:42] Fine-tune failed. Fine-tune will exceed free trial credits\\n\\nJob failed. Please contact us through our help center at help.openai.com if you need assistance.\\n\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = subprocess.run('openai api fine_tunes.list'.split(), stdout=subprocess.PIPE).stdout\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iqXluBj5oyjh",
        "outputId": "ba37a8dc-159c-46ff-d68f-b7cedff4e724"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'{\\n  \"object\": \"list\",\\n  \"data\": [\\n    {\\n      \"object\": \"fine-tune\",\\n      \"id\": \"ft-DUHvHf64kCgg4NZXCIoFx03Y\",\\n      \"hyperparams\": {\\n        \"n_epochs\": 4,\\n        \"batch_size\": null,\\n        \"prompt_loss_weight\": 0.01,\\n        \"learning_rate_multiplier\": null\\n      },\\n      \"organization_id\": \"org-LsRSFcCdezFMWrF1yYEd6eYe\",\\n      \"model\": \"curie\",\\n      \"training_files\": [\\n        {\\n          \"object\": \"file\",\\n          \"id\": \"file-eoIlel2JuBwCBGq8EaYoL44f\",\\n          \"purpose\": \"fine-tune\",\\n          \"filename\": \"data/prepared_data_prepared.jsonl\",\\n          \"bytes\": 446199,\\n          \"created_at\": 1696472353,\\n          \"status\": \"processed\",\\n          \"status_details\": null\\n        }\\n      ],\\n      \"validation_files\": [],\\n      \"result_files\": [],\\n      \"created_at\": 1696472353,\\n      \"updated_at\": 1696472377,\\n      \"status\": \"failed\",\\n      \"fine_tuned_model\": null\\n    },\\n    {\\n      \"object\": \"fine-tune\",\\n      \"id\": \"ft-XQtqlfiK0vt629xbTKohD9gL\",\\n      \"hyperparams\": {\\n        \"n_epochs\": 4,\\n        \"batch_size\": null,\\n        \"prompt_loss_weight\": 0.01,\\n        \"learning_rate_multiplier\": null\\n      },\\n      \"organization_id\": \"org-LsRSFcCdezFMWrF1yYEd6eYe\",\\n      \"model\": \"curie\",\\n      \"training_files\": [\\n        {\\n          \"object\": \"file\",\\n          \"id\": \"file-lujkljdVWAzs9dHFYqoIh4UY\",\\n          \"purpose\": \"fine-tune\",\\n          \"filename\": \"data/prepared_data_prepared.jsonl\",\\n          \"bytes\": 446199,\\n          \"created_at\": 1696473213,\\n          \"status\": \"processed\",\\n          \"status_details\": null\\n        }\\n      ],\\n      \"validation_files\": [],\\n      \"result_files\": [],\\n      \"created_at\": 1696473214,\\n      \"updated_at\": 1696473238,\\n      \"status\": \"failed\",\\n      \"fine_tuned_model\": null\\n    }\\n  ],\\n  \"next_starting_after\": null\\n}\\n'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "output = subprocess.run('openai api fine_tunes.results -i ft-gUum6Ej7gYJghTfFcmdwkeHJ'.split(), stdout=subprocess.PIPE).stdout\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8VH8kTS5twIc",
        "outputId": "7182fe76-3ed4-463e-9b1d-39a5e201b8d9"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b''\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "def write_a_story(prompt):\n",
        "    response = openai.Completion.create(\n",
        "        model=\"curie:ft-bothub-ai:ultraman-2023-04-04-03-03-26\",\n",
        "        prompt=prompt,\n",
        "        temperature=0.7,\n",
        "        max_tokens=2000,\n",
        "        top_p=1,\n",
        "        stop=[\".\"])\n",
        "    return response[\"choices\"][0][\"text\"]\n",
        "\n",
        "story = write_a_story(\"宋,发射激光,艰难 ->\\n\")\n",
        "print(story)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "id": "R_IqTeL_pklO",
        "outputId": "09acf264-273a-4b33-fa4e-1414767f013a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "InvalidRequestError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidRequestError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-0d725e1e9751>\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"choices\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mstory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrite_a_story\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"宋,发射激光,艰难 ->\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-0d725e1e9751>\u001b[0m in \u001b[0;36mwrite_a_story\u001b[0;34m(prompt)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mwrite_a_story\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     response = openai.Completion.create(\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ft-XQtqlfiK0vt629xbTKohD9gL\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mprompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_resources/completion.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTryAgain\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_resources/abstract/engine_api_resource.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    153\u001b[0m         )\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m         response, _, api_key = requestor.request(\n\u001b[0m\u001b[1;32m    156\u001b[0m             \u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m             \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0mrequest_timeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m         )\n\u001b[0;32m--> 299\u001b[0;31m         \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgot_stream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_interpret_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgot_stream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    708\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m             return (\n\u001b[0;32m--> 710\u001b[0;31m                 self._interpret_response_line(\n\u001b[0m\u001b[1;32m    711\u001b[0m                     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m                     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    773\u001b[0m         \u001b[0mstream_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstream\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"error\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    774\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstream_error\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mrcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 775\u001b[0;31m             raise self.handle_error_response(\n\u001b[0m\u001b[1;32m    776\u001b[0m                 \u001b[0mrbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m             )\n",
            "\u001b[0;31mInvalidRequestError\u001b[0m: The model `ft-XQtqlfiK0vt629xbTKohD9gL` does not exist"
          ]
        }
      ]
    }
  ]
}