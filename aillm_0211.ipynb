{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HUJameson/Colab/blob/main/aillm_0211.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RVnIJDw39Wf4",
        "outputId": "9258f71c-0fcc-476c-e6fe-ddaa80220c4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "os.chdir(\"/content/drive/My Drive/Colab Notebooks\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cmdJ2KJo9nAK"
      },
      "outputs": [],
      "source": [
        "!pip install openai\n",
        "import openai\n",
        "from sk_utils import read_sk\n",
        "openai_sk = read_sk()\n",
        "%env OPENAI_API_KEY=$openai_sk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fafT9fwW9JyF",
        "outputId": "917536cc-4c80-47e4-c91e-2ad6cd22ef12"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "欢迎来到ONBOARD,真实的一线经验,走新的投资思考。我是Monica。 我是高宁。我们一起聊聊软件如何改变世界。 大家好,欢迎来到ONBOARD,我是Monica。 自从OpenAI发布的ChatGBT掀起了席卷世界的AI热潮,不到三个月就积累了超过一亿的越活用户,超过1300万的日活用户。 真的是展现了AI让人惊叹的能力,也让很多人直呼这就是下一个互联网的未来。 有不少观众都说希望我们再做一期AI的讨论,于是这次硬核讨论就来了。 这次我们请来了Google Brain的研究员雪芝,她是Google大语言模型POM,Pathway Language Model的作者之一。 要知道,这个模型的参数量是GPT-3的三倍还多。 另外还有两位AI产品大牛,一位来自著名的Stable Diffusion背后的商业公司Stability AI, 另一位来自某硅谷科技大厂,也曾在吴恩达教授的Landing AI中担任产品负责人。 此外,Monica还邀请到一位一直关注AI的投资人朋友Bill,当做我的特邀共同主持嘉宾。 我们主要讨论几个话题,一方面从研究的视角,最前沿的研究者在关注什么? 现在技术的天花板和未来大的变量可能会在哪里? 从产品和商业的角度,什么是一个好的AI产品? 整个生态可能随着技术有怎样的演变? 更重要的,我们又能从上一波AI的创业热潮中学到什么? 最后,Monica和Bill还会从投资人的视角做一个回顾、总结和畅想。 这里还有一个小的update,在本集发布的时候,Google也对爆发式增长的Chat GPT做出了回应。 正在测试一个基于Lambda模型的聊天机器人ApprenticeBot。 证实发布后会有怎样的惊喜,我们都拭目以待。 AI无疑是未来几年最令人兴奋的变量之一。 Monica也希望未来能邀请到更多一线从业者从不同角度讨论这个话题。 不论是想要做创业、研究、产品还是投资的同学, 希望这些对话对于大家了解这些技术演进、商业的可能, 甚至未来对于我们每个人、每个社会意味着什么都能引发一些思考,提供一些启发。 这次的讨论有些技术硬核,需要各位对生成式AI大模型都有一些基础了解。 讨论中涉及到的论文和重要概念也会总结在本集的简介中,供大家复习参考。 几位嘉宾在北美工作生活多年,夹杂英文在所难免,也请大家体谅了。 欢迎来到未来,大家enjoy!\n"
          ]
        }
      ],
      "source": [
        "import openai, os\n",
        "\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "audio_file= open(\"./data/podcast/podcast_clip.mp3\", \"rb\")\n",
        "transcript = openai.Audio.transcribe(\"whisper-1\", audio_file)\n",
        "print(transcript['text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V8vDfNvACkoH",
        "outputId": "7600aa8f-ce66-432b-db12-d1ef18c22d97"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Zither Harp 春暖的花開帶走冬天的感傷 微風吹來浪漫的氣息 每一首情歌忽然充滿意義 我就在此刻突然見到你 春暖的花香帶走冬天的寂寒 微風吹來意外的愛情 鳥兒的高歌拉近我們距離 我就在此刻突然愛上你 聽我說 手牽手 跟我一起走 創造幸福的生活 昨天已來不及 明天就會可惜 今天嫁給我好嗎 Jolene in the house DT in the house Jolene in the house DT in the house Jolene in the house DT in the house Our love in the house Sweet sweet love 夏日的熱情打動春天的藍傘 陽光照耀美滿的家庭 每一首情歌都會勾起回憶 想當年我是怎麼認識你 But you know 冬天的憂傷解釋秋天的孤單 微風吹來哭了的思念 鳥兒的高歌唱著不要別離 此刻我多麼想要擁抱你 聽我說 手牽手 跟我一起走 過著安定的生活 昨天已來不及 明天就會可惜 今天你要嫁給我 聽我說 手牽手 我們一起走 把你一生交給我 昨天不要回頭 明天要到白首 今天你要嫁給我 叮噹 聽著禮堂的鐘聲 我們在上帝和親友面前見證 這對男女現在就要結為夫妻 不要忘了這一切是多麼的神聖 你願意生死苦樂永遠和他在一起 愛惜他 尊重他 安慰他 保護著他 兩人重新建立起美滿的家庭 你願意這樣做嗎 Yes I do 聽我說 手牽手 一路到盡頭 把你一生交給我 昨天已是過去 明天更多回憶 今天你要嫁給我 今天你要嫁給我 今天你要嫁給我\n"
          ]
        }
      ],
      "source": [
        "audio_file= open(\"./data/podcast/taozhe-1.mp3\", \"rb\")\n",
        "transcript = openai.Audio.transcribe(\"whisper-1\", audio_file)\n",
        "print(transcript['text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NMJr-hFVEuii"
      },
      "outputs": [],
      "source": [
        "audio_file= open(\"./data/podcast/taozhe-1.mp3\", \"rb\")\n",
        "transcript = openai.Audio.transcribe(\"whisper-1\", audio_file, prompt=\"这是一首中文歌曲。\", response_format=\"srt\")\n",
        "print(transcript)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3CjF8pq1C-m_",
        "outputId": "74dc1dfc-b648-476d-e9dc-2f31dd2e7535"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "欢迎来到onboard,真实的一线经验,走新的投资思考。我是莫妮卡。 我是高宁。我们一起聊聊软件如何改变世界。 大家好,欢迎来到onboard,我是莫妮卡。 自从OpenAI发布的ChatGBT掀起了席卷世界的AI热潮, 不到三个月就积累了超过一亿的越活用户,超过一千三百万的日活用户。 真的是展现了AI让人惊叹的能力,也让很多人直呼这就是下一个互联网的未来。 有不少观众都说希望我们再做一期AI的讨论,于是这次硬核讨论就来了。 这次我们请来了Google Brain的研究员雪芝, 她是Google大语言模型POM,Pathway Language Model的作者之一。 要知道,这个模型的参数量是GPT-3的三倍还多。 另外还有两位AI产品大牛,一位来自著名的Stable Diffusion背后的商业公司Stability AI, 另一位来自某硅谷科技大厂,也曾在吴恩达教授的Landing AI中担任产品负责人。 此外,莫妮卡还邀请到一位一直关注AI的投资人朋友Bill当做我的特邀共同主持嘉宾。 我们主要讨论几个话题,一方面从研究的视角,最前沿的研究者在关注什么? 现在的技术的天花板和未来大的变量可能会在哪里? 从产品和商业的角度,什么是一个好的AI产品? 整个生态可能随着技术有怎样的演变? 更重要的,我们又能从上一波AI的创业热潮中学到什么? 最后,莫妮卡和Bill还会从投资人的视角做一个回顾、总结和畅想。 这里还有一个小的update,在本集发布的时候, Google也对爆发式增长的ChatGBT做出了回应, 正在测试一个基于Lambda模型的聊天机器人ApprenticeBot。 证实发布后会有怎样的惊喜,我们都拭目以待。 AI无疑是未来几年最令人兴奋的变量之一, 莫妮卡也希望未来能邀请到更多一线从业者从不同角度讨论这个话题。 不论是想要做创业、研究、产品还是投资的同学, 希望这些对话对于大家了解这些技术演进、商业的可能, 甚至未来对于我们每个人、每个社会意味着什么都能引发一些思考,提供一些启发。 这次的讨论有些技术硬核,需要各位对生成式AI、大模型都有一些基础了解。 讨论中涉及到的论文和重要概念也会总结在本集的简介中,供大家复习参考。 几位嘉宾在北美工作生活多年,夹杂英文在所难免,也请大家体谅了。 欢迎来到未来,大家enjoy!\n"
          ]
        }
      ],
      "source": [
        "audio_file= open(\"./data/podcast/podcast_clip.mp3\", \"rb\")\n",
        "transcript = openai.Audio.transcribe(\"whisper-1\", audio_file, prompt=\"这是一段中文播客内容。\")\n",
        "print(transcript['text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o4MgkgFTDi8i",
        "outputId": "4d023cc7-be52-414b-a4a6-d758ca56c104"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "欢迎来到Onboard,真实的一线经验,走新的投资思考。我是Monica。 我是高宁,我们一起聊聊软件如何改变世界。 大家好,欢迎来到Onboard,我是Monica。 自从OpenAI发布的ChatGPT掀起了席卷世界的AI热潮,不到三个月就积累了超过一亿的越活用户,超过1300万的日活用户。 真的是展现了AI让人惊叹的能力,也让很多人直呼这就是下一个互联网的未来。 有不少观众都说希望我们再做一期AI的讨论,于是这次硬核讨论就来了。 这次我们请来了Google Brain的研究员雪芝,她是Google大语言模型PALM Pathways Language Model的作者之一。 要知道,这个模型的参数量是GPT-3的三倍还多。 另外还有两位AI产品大牛,一位来自著名的Stable Diffusion背后的商业公司Stability AI, 另一位来自某硅谷科技大厂,也曾在吴恩达教授的Landing AI中担任产品负责人。 此外,Monica还邀请到一位一直关注AI的投资人朋友Bill当做我的特邀共同主持嘉宾。 我们主要讨论几个话题,一方面从研究的视角,最前沿的研究者在关注什么? 现在技术的天花板和未来大的变量可能会在哪里? 从产品和商业的角度,什么是一个好的AI产品? 整个生态可能随着技术有怎样的演变? 更重要的,我们又能从上一波AI的创业热潮中学到什么? 最后,Monica和Bill还会从投资人的视角做一个回顾、总结和畅想。 这里还有一个小的update,在本集发布的时候,Google也对爆发式增长的Chat GPT做出了回应。 正在测试一个基于Lambda模型的聊天机器人ApprenticeBot。 证实发布后会有怎样的惊喜,我们都拭目以待。 AI无疑是未来几年最令人兴奋的变量之一。 Monica也希望未来能邀请到更多一线从业者从不同角度讨论这个话题。 不论是想要做创业、研究、产品还是投资的同学, 希望这些对话对于大家了解这些技术演进、商业的可能, 甚至未来对于我们每个人、每个社会意味着什么都能引发一些思考,提供一些启发。 这次的讨论有些技术硬核,需要各位对生成式AI大模型都有一些基础了解。 讨论中涉及到的论文和重要概念也会总结在本集的简介中,供大家复习参考。 几位嘉宾在北美工作生活多年,夹杂英文在所难免,也请大家体谅了。 欢迎来到未来,大家enjoy!\n"
          ]
        }
      ],
      "source": [
        "audio_file= open(\"./data/podcast/podcast_clip.mp3\", \"rb\")\n",
        "transcript = openai.Audio.transcribe(\"whisper-1\", audio_file,\n",
        "                                     prompt=\"这是一段Onboard播客，里面会聊到ChatGPT以及PALM这个大语言模型。这个模型也叫做Pathways Language Model。\")\n",
        "print(transcript['text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NUosEcseKVAk",
        "outputId": "f61c3f98-dcc8-43e9-f2b7-38b17b9dff3c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Welcome to Onboard. Real first-line experience. New investment thinking. I'm Monica. I'm Gao Ning. Let's talk about how software can change the world. Hello everyone, welcome to Onboard. I'm Monica. Since the release of ChatGPT by OpenAI, it has aroused the popularity of AI in the world. In less than three months, it has accumulated more than 100 million active users, and more than 13 million active users. It really shows the ability of AI to amaze people. It also makes a lot of people say, this is the future of the next Internet. Many viewers said they wanted us to do another episode of AI discussion. So this discussion came. This time we invited a researcher from Google Brain, Xue Zhi. He is one of the authors of Google's large-scale PaLM model, Pathways Language Model. You should know that the number of parameters of this model is three times more than ChatGPT-3. In addition, there are two AI product bigwigs, one is from a well-known business company behind Stable Diffusion, Stability AI, and the other is from a Silicon Valley technology factory. He was also the product manager in Professor Wanda's Landing AI. In addition, Monica also invited a friend who has been paying attention to AI, Bill, to be my special guest host. We mainly discussed a few topics. On the one hand, from the perspective of research, what are the most cutting-edge researchers paying attention to? Where are the cutting-edge technologies and the big changes in the future? From the perspective of products and business, what is a good AI product? How will the whole ecosystem evolve with technology? More importantly, what can we learn from the last wave of AI entrepreneurship? Finally, Monica and Bill will also make a review, summarize and imagine from the perspective of investors. Here is a small update. When this episode was released, Google also responded to the explosive growth of ChatGPT. We are testing a chat robot based on Lambda, ApprenticeBot. What kind of surprises will come after the official release? We are all looking forward to it. AI is one of the most exciting variables in the next few years. Monica also hopes to invite more first-line entrepreneurs to discuss this topic from different angles. Whether you want to start a business, research, product, or investment, I hope these conversations will help you understand the possibilities of technology, business, and even what it means to each of us in the future, to each society. It can trigger some thoughts and inspire us. This discussion is a bit technical, and requires you to have some basic understanding of biometric AI and big models. The papers and important concepts involved in the discussion will also be summarized in this episode's introduction, for your reference. Several guests have worked in North America for many years, so it is inevitable to mix up the English. Please understand. Welcome to the future. Enjoy!\n"
          ]
        }
      ],
      "source": [
        "audio_file= open(\"./data/podcast/podcast_clip.mp3\", \"rb\")\n",
        "translated_prompt=\"\"\"This is a podcast discussing ChatGPT and PaLM model.\n",
        "The full name of PaLM is Pathways Language Model.\"\"\"\n",
        "transcript = openai.Audio.translate(\"whisper-1\", audio_file,\n",
        "                                    prompt=translated_prompt)\n",
        "print(transcript['text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_xd00bskT-GQ"
      },
      "outputs": [],
      "source": [
        "!ffmpeg -i ./data/podcast/test-1.mp4 -vn -c:a libmp3lame -q:a 4 ./data/podcast/test-1.mp3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0cghBwsdU7Ab"
      },
      "outputs": [],
      "source": [
        "!pip install -U pydub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VWPTD2JBVGRt"
      },
      "outputs": [],
      "source": [
        "from pydub import AudioSegment\n",
        "\n",
        "podcast = AudioSegment.from_mp3(\"./data/podcast/test-1.mp3\")\n",
        "\n",
        "# PyDub handles time in milliseconds\n",
        "ten_minutes = 15 * 60 * 1000\n",
        "\n",
        "total_length = len(podcast)\n",
        "\n",
        "start = 0\n",
        "index = 0\n",
        "while start < total_length:\n",
        "    end = start + ten_minutes\n",
        "    if end < total_length:\n",
        "        chunk = podcast[start:end]\n",
        "    else:\n",
        "        chunk = podcast[start:]\n",
        "    with open(f\"./data/podcast/test-1_{index}.mp3\", \"wb\") as f:\n",
        "        chunk.export(f, format=\"mp3\")\n",
        "    start = end\n",
        "    index += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TbArBKh_XAoc"
      },
      "outputs": [],
      "source": [
        "prompt = \"这是一段中文播客。\"\n",
        "for i in range(index):\n",
        "    clip = f\"./data/podcast/test-1_{i}.mp3\"\n",
        "    audio_file= open(clip, \"rb\")\n",
        "    transcript = openai.Audio.transcribe(\"whisper-1\", audio_file,\n",
        "                                     prompt=prompt)\n",
        "    # mkdir ./data/transcripts if not exists\n",
        "    if not os.path.exists(\"./podcast/data/transcripts\"):\n",
        "        os.makedirs(\"./data/podcast/transcripts\")\n",
        "    # write to file\n",
        "    with open(f\"./data/podcast/transcripts/test_1_{i}.txt\", \"w\") as f:\n",
        "        f.write(transcript['text'])\n",
        "    # get last sentence of the transcript\n",
        "    sentences = transcript['text'].split(\"。\")\n",
        "    prompt = sentences[-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m2h6orZILjG6"
      },
      "outputs": [],
      "source": [
        "!pip install openai-whisper\n",
        "!pip install setuptools-rust"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "model = whisper.load_model(\"large\")"
      ],
      "metadata": {
        "id": "UP132FG8K5Ja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6T8OdJ6uTWSa",
        "outputId": "17b405d8-e8bd-4358-8d5c-da24f7ae63cd"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "./data/podcast/test-1_0.mp3\n",
            "这是一段中文播客。\n",
            "\n",
            "\n",
            "./data/podcast/transcripts/local_test-1_0.txt\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:114: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        }
      ],
      "source": [
        "\n",
        "index = 2\n",
        "\n",
        "def transcript(clip, prompt, output):\n",
        "    print(clip)\n",
        "    print(prompt)\n",
        "    print(output)\n",
        "    result = model.transcribe(clip, initial_prompt=prompt)\n",
        "    print(result['text'])\n",
        "    with open(output, \"w\") as f:\n",
        "        f.write(result['text'])\n",
        "    print(\"Transcripted: \", clip)\n",
        "\n",
        "original_prompt = \"这是一段中文播客。\\n\\n\"\n",
        "prompt = original_prompt\n",
        "for i in range(index):\n",
        "    clip = f\"./data/podcast/test-1_{i}.mp3\"\n",
        "    output = f\"./data/podcast/transcripts/local_test-1_{i}.txt\"\n",
        "    transcript(clip, prompt, output)\n",
        "    # get last sentence of the transcript\n",
        "    with open(output, \"r\") as f:\n",
        "        transcript = f.read()\n",
        "    sentences = transcript.split(\"。\")\n",
        "    prompt = original_prompt + sentences[-1]"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMHNrM1HM4eljlXzG+8tCvp",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}