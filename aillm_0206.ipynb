{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMKEvfRCPDCx4JMB24JejS1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HUJameson/Colab/blob/main/aillm_0206.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "os.chdir(\"/content/drive/My Drive/Colab Notebooks\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "88rXt-LLZyc_",
        "outputId": "33abbbab-c860-4493-8a4e-43777447afd8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai\n",
        "import openai\n",
        "from sk_utils import read_sk\n",
        "openai_sk = read_sk()\n",
        "%env OPENAI_API_KEY=$openai_sk"
      ],
      "metadata": {
        "id": "ZpcKsdVnaQa3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GOlVh8Z2MgeW"
      },
      "outputs": [],
      "source": [
        "!pip install langchain\n",
        "import openai, os\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.chains import LLMChain\n",
        "\n",
        "openai.api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
        "\n",
        "llm = OpenAI(model_name=\"text-davinci-003\", max_tokens=2048, temperature=0.5)\n",
        "\n",
        "en_to_zh_prompt = PromptTemplate(\n",
        "    template=\"请把下面这句话翻译成英文： \\n\\n {question}?\", input_variables=[\"question\"]\n",
        ")\n",
        "\n",
        "question_prompt = PromptTemplate(\n",
        "    template = \"{english_question}\", input_variables=[\"english_question\"]\n",
        ")\n",
        "\n",
        "zh_to_cn_prompt = PromptTemplate(\n",
        "    input_variables=[\"english_answer\"],\n",
        "    template=\"请把下面这一段翻译成中文： \\n\\n{english_answer}?\",\n",
        ")\n",
        "\n",
        "question_translate_chain = LLMChain(llm=llm, prompt=en_to_zh_prompt, output_key=\"english_question\")\n",
        "english = question_translate_chain.run(question=\"请你作为一个机器学习的专家，介绍一下CNN的原理。\")\n",
        "print(english)\n",
        "\n",
        "qa_chain = LLMChain(llm=llm, prompt=question_prompt, output_key=\"english_answer\")\n",
        "english_answer = qa_chain.run(english_question=english)\n",
        "print(english_answer)\n",
        "\n",
        "answer_translate_chain = LLMChain(llm=llm, prompt=zh_to_cn_prompt)\n",
        "answer = answer_translate_chain.run(english_answer=english_answer)\n",
        "print(answer)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import SimpleSequentialChain\n",
        "\n",
        "chinese_qa_chain = SimpleSequentialChain(\n",
        "    chains=[question_translate_chain, qa_chain, answer_translate_chain], input_key=\"question\",\n",
        "    verbose=True)\n",
        "answer = chinese_qa_chain.run(question=\"请你作为一个机器学习的专家，介绍一下CNN的原理。\")\n",
        "print(answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hdpp7uYcbsu-",
        "outputId": "dcbcaabc-bf28-4ccb-9ae4-bba8de01cc8c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
            "\u001b[36;1m\u001b[1;3m\n",
            "\n",
            "Please explain the principle of CNN as an expert in machine learning.\u001b[0m\n",
            "\u001b[33;1m\u001b[1;3m\n",
            "\n",
            "Convolutional Neural Networks (CNNs) are a type of deep learning neural network used for image recognition and classification. CNNs use a combination of convolutional layers, pooling layers, and fully connected layers to learn features from an input image and then classify or recognize it. The convolutional layers process the input image in a series of convolutions, which are small matrix multiplications that extract features from the image. The pooling layers then reduce the size of the feature map, while the fully connected layers provide the output classification. The weights and parameters of the CNN are learned through backpropagation, which is a process of updating the weights and parameters based on the error of the output classification.\u001b[0m\n",
            "\u001b[38;5;200m\u001b[1;3m\n",
            "\n",
            "卷积神经网络（CNN）是一种深度学习神经网络，用于图像识别和分类。CNN使用卷积层，池化层和完全连接层的组合来从输入图像中学习特征，然后进行分类或识别。卷积层以一系列卷积的方式处理输入图像，这些卷积是从图像中提取特征的小矩阵乘法。池化层然后减小特征映射的大小，而完全连接层提供输出分类。CNN的权重和参数通过反向传播来学习，这是一种基于输出分类误差更新权重和参数的过程。\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "卷积神经网络（CNN）是一种深度学习神经网络，用于图像识别和分类。CNN使用卷积层，池化层和完全连接层的组合来从输入图像中学习特征，然后进行分类或识别。卷积层以一系列卷积的方式处理输入图像，这些卷积是从图像中提取特征的小矩阵乘法。池化层然后减小特征映射的大小，而完全连接层提供输出分类。CNN的权重和参数通过反向传播来学习，这是一种基于输出分类误差更新权重和参数的过程。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import SequentialChain\n",
        "\n",
        "q1_prompt = PromptTemplate(\n",
        "    input_variables=[\"year1\"],\n",
        "    template=\"{year1}年的欧冠联赛的冠军是哪支球队，只说球队名称。\"\n",
        ")\n",
        "q2_prompt = PromptTemplate(\n",
        "    input_variables=[\"year2\"],\n",
        "    template=\"{year2}年的欧冠联赛的冠军是哪支球队，只说球队名称。\"\n",
        ")\n",
        "q3_prompt = PromptTemplate(\n",
        "    input_variables=[\"team1\", \"team2\"],\n",
        "    template=\"{team1}和{team2}哪只球队获得欧冠的次数多一些？\"\n",
        ")\n",
        "chain1 = LLMChain(llm=llm, prompt=q1_prompt, output_key=\"team1\")\n",
        "chain2 = LLMChain(llm=llm, prompt=q2_prompt, output_key=\"team2\")\n",
        "chain3 = LLMChain(llm=llm, prompt=q3_prompt)\n",
        "\n",
        "sequential_chain = SequentialChain(chains=[chain1, chain2, chain3], input_variables=[\"year1\", \"year2\"], verbose=True)\n",
        "answer = sequential_chain.run(year1=2000, year2=2010)\n",
        "print(answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O8UbcMObcLPS",
        "outputId": "4fb26fda-8f1f-4a80-a039-f08a03799f00"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "法国巴黎圣日耳曼队获得欧冠的次数多于西班牙皇家马德里队，共计6次，而皇家马德里队只获得3次。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import SequentialChain\n",
        "\n",
        "def write_unit_test(function_to_test, unit_test_package = \"pytest\"):\n",
        "    # 解释源代码的步骤\n",
        "    explain_code = \"\"\"\"# How to write great unit tests with {unit_test_package}\n",
        "\n",
        "    In this advanced tutorial for experts, we'll use Python 3.10 and `{unit_test_package}` to write a suite of unit tests to verify the behavior of the following function.\n",
        "    ```python\n",
        "    {function_to_test}\n",
        "    ```\n",
        "\n",
        "    Before writing any unit tests, let's review what each element of the function is doing exactly and what the author's intentions may have been.\n",
        "    - First,\"\"\"\n",
        "\n",
        "    explain_code_template = PromptTemplate(\n",
        "        input_variables=[\"unit_test_package\", \"function_to_test\"],\n",
        "        template=explain_code\n",
        "    )\n",
        "    explain_code_llm = OpenAI(model_name=\"text-davinci-002\", temperature=0.4, max_tokens=1000,\n",
        "            top_p=1, stop=[\"\\n\\n\", \"\\n\\t\\n\", \"\\n    \\n\"])\n",
        "    explain_code_step = LLMChain(llm=explain_code_llm, prompt=explain_code_template, output_key=\"code_explaination\")\n",
        "\n",
        "    # 创建测试计划示例的步骤\n",
        "    test_plan = \"\"\"\n",
        "\n",
        "    A good unit test suite should aim to:\n",
        "    - Test the function's behavior for a wide range of possible inputs\n",
        "    - Test edge cases that the author may not have foreseen\n",
        "    - Take advantage of the features of `{unit_test_package}` to make the tests easy to write and maintain\n",
        "    - Be easy to read and understand, with clean code and descriptive names\n",
        "    - Be deterministic, so that the tests always pass or fail in the same way\n",
        "\n",
        "    `{unit_test_package}` has many convenient features that make it easy to write and maintain unit tests. We'll use them to write unit tests for the function above.\n",
        "\n",
        "    For this particular function, we'll want our unit tests to handle the following diverse scenarios (and under each scenario, we include a few examples as sub-bullets):\n",
        "    -\"\"\"\n",
        "    test_plan_template = PromptTemplate(\n",
        "        input_variables=[\"unit_test_package\", \"function_to_test\", \"code_explaination\"],\n",
        "        template= explain_code + \"{code_explaination}\" + test_plan\n",
        "    )\n",
        "    test_plan_llm = OpenAI(model_name=\"text-davinci-002\", temperature=0.4, max_tokens=1000,\n",
        "            top_p=1, stop=[\"\\n\\n\", \"\\n\\t\\n\", \"\\n    \\n\"])\n",
        "    test_plan_step = LLMChain(llm=test_plan_llm, prompt=test_plan_template, output_key=\"test_plan\")\n",
        "\n",
        "    # 撰写测试代码的步骤\n",
        "    starter_comment = \"Below, each test case is represented by a tuple passed to the @pytest.mark.parametrize decorator\"\n",
        "    prompt_to_generate_the_unit_test = \"\"\"\n",
        "\n",
        "Before going into the individual tests, let's first look at the complete suite of unit tests as a cohesive whole. We've added helpful comments to explain what each line does.\n",
        "```python\n",
        "import {unit_test_package}  # used for our unit tests\n",
        "\n",
        "{function_to_test}\n",
        "\n",
        "#{starter_comment}\"\"\"\n",
        "\n",
        "    unit_test_template = PromptTemplate(\n",
        "        input_variables=[\"unit_test_package\", \"function_to_test\", \"code_explaination\", \"test_plan\", \"starter_comment\"],\n",
        "        template= explain_code + \"{code_explaination}\" + test_plan + \"{test_plan}\" + prompt_to_generate_the_unit_test\n",
        "    )\n",
        "    unit_test_llm = OpenAI(model_name=\"text-davinci-002\", temperature=0.4, max_tokens=1000, stop=\"```\")\n",
        "    unit_test_step = LLMChain(llm=unit_test_llm, prompt=unit_test_template, output_key=\"unit_test\")\n",
        "\n",
        "    sequential_chain = SequentialChain(chains=[explain_code_step, test_plan_step, unit_test_step],\n",
        "                                    input_variables=[\"unit_test_package\", \"function_to_test\", \"starter_comment\"], verbose=True)\n",
        "    answer = sequential_chain.run(unit_test_package=unit_test_package, function_to_test=function_to_test, starter_comment=starter_comment)\n",
        "    return f\"\"\"#{starter_comment}\"\"\" + answer\n",
        "\n",
        "code = \"\"\"\n",
        "def format_time(seconds):\n",
        "    minutes, seconds = divmod(seconds, 60)\n",
        "    hours, minutes = divmod(minutes, 60)\n",
        "    if hours > 0:\n",
        "        return f\"{hours}h{minutes}min{seconds}s\"\n",
        "    elif minutes > 0:\n",
        "        return f\"{minutes}min{seconds}s\"\n",
        "    else:\n",
        "        return f\"{seconds}s\"\n",
        "\"\"\"\n",
        "\n",
        "import ast\n",
        "\n",
        "def write_unit_test_automatically(code, retry=3):\n",
        "    unit_test_code = write_unit_test(code)\n",
        "    all_code = code + unit_test_code\n",
        "    tried = 0\n",
        "    while tried < retry:\n",
        "        try:\n",
        "            ast.parse(all_code)\n",
        "            return all_code\n",
        "        except SyntaxError as e:\n",
        "            print(f\"Syntax error in generated code: {e}\")\n",
        "            all_code = code + write_unit_test(code)\n",
        "            tried += 1\n",
        "\n",
        "print(write_unit_test_automatically(code))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TyuBQfRdctmd",
        "outputId": "bbec1090-42a3-471b-e447-029367b75491"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "def format_time(seconds):\n",
            "    minutes, seconds = divmod(seconds, 60)\n",
            "    hours, minutes = divmod(minutes, 60)\n",
            "    if hours > 0:\n",
            "        return f\"{hours}h{minutes}min{seconds}s\"\n",
            "    elif minutes > 0:\n",
            "        return f\"{minutes}min{seconds}s\"\n",
            "    else:\n",
            "        return f\"{seconds}s\"\n",
            "#Below, each test case is represented by a tuple passed to the @pytest.mark.parametrize decorator.\n",
            "#The first element of the tuple is the name of the test case, and the second element is a list of parameters to be passed to the test function.\n",
            "@pytest.mark.parametrize(\"test_case, expected\", [\n",
            "    # Test cases for positive integers\n",
            "    (\"1 second\", \"1s\"),\n",
            "    (\"60 seconds\", \"1min\"),\n",
            "    (\"3600 seconds\", \"1h\"),\n",
            "    (\"86400 seconds\", \"1d\"),\n",
            "    # Test cases for negative integers\n",
            "    (\"-1 second\", \"-1s\"),\n",
            "    (\"-60 seconds\", \"-1min\"),\n",
            "    (\"-3600 seconds\", \"-1h\"),\n",
            "    (\"-86400 seconds\", \"-1d\"),\n",
            "    # Test case for zero\n",
            "    (\"0 seconds\", \"0s\"),\n",
            "    # Test cases for floats\n",
            "    (\"1.5 seconds\", \"1.5s\"),\n",
            "    (\"60.5 seconds\", \"1min\"),\n",
            "    (\"3600.5 seconds\", \"1h\"),\n",
            "    (\"86400.5 seconds\", \"1d\"),\n",
            "    # Test cases for strings\n",
            "    (\"'1' second\", \"1s\"),\n",
            "    (\"'60' seconds\", \"1min\"),\n",
            "    (\"'3600' seconds\", \"1h\"),\n",
            "    (\"'86400' seconds\", \"1d\"),\n",
            "    # Test case for None\n",
            "    (\"None\", \"0s\"),\n",
            "    # Test case for a list\n",
            "    (\"[1, 2, 3]\", \"0s\"),\n",
            "    # Test case for a tuple\n",
            "    (\"(1, 2, 3)\", \"0s\"),\n",
            "    # Test case for a dict\n",
            "    (\"{'a': 1, 'b': 2, 'c': 3}\", \"0s\"),\n",
            "    # Test case for a set\n",
            "    (\"{1, 2, 3}\", \"0s\"),\n",
            "    # Test case for a bool\n",
            "    (\"True\", \"0s\"),\n",
            "    # Test case for an object\n",
            "    (\"object()\", \"0s\"),\n",
            "    # Test case for a complex number\n",
            "    (\"1+2j\", \"0s\"),\n",
            "])\n",
            "def test_format_time(test_case, expected):\n",
            "    # The test function takes the name of the test case and the expected output as parameters.\n",
            "    # We use the pytest.approx builtin to compare floats, since we don't want our tests to fail\n",
            "    # due to rounding errors.\n",
            "    assert format_time(test_case) == pytest.approx(expected)\n",
            "\n"
          ]
        }
      ]
    }
  ]
}